# Grimperium Architecture

**Document Version:** 2.2.0
**Last Updated:** 2026-01-28
**Next Review:** 2026-06-19 (or after 100K molecules processed)
**Version:** v2.2
**Status:** Production-Ready (Single-Process)

## Table of Contents

1. [System Overview](#system-overview)
2. [Known Limitations](#known-limitations)
3. [Data Flow](#data-flow)
4. [Future Considerations](#future-considerations)
5. [Decision Log](#decision-log)

---

## System Overview

### High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   GRIMPERIUM v2.2                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚  CLI Layer (main.py)                                â”‚
â”‚  â†“                                                  â”‚
â”‚  BatchOrchestrator (coordinator)                    â”‚
â”‚  â”œâ”€ BatchDataManager (load CSV)                     â”‚
â”‚  â”œâ”€ BatchScheduler (prioritize)                     â”‚
â”‚  â”œâ”€ CalculationExecutor (CREST + MOPAC)             â”‚
â”‚  â”œâ”€ MoleculePersister (atomic writes)               â”‚
â”‚  â””â”€ BatchReporter (summaries)                       â”‚
â”‚  â†“                                                  â”‚
â”‚  CSV Backend (thermo_pm7.csv)                       â”‚
â”‚  â†“                                                  â”‚
â”‚  ~/.grimperium/config.toml (settings)               â”‚
â”‚  ~/.grimperium/validation_errors.log (audit)        â”‚
â”‚  ~/.grimperium/batch_summary.log (history)          â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Rationale |
|-----------|-----------|-----------|
| **Data Format** | CSV | Simple, auditable, versionable in git |
| **Settings** | TOML | Human-readable, standardized |
| **In-Memory** | Pandas DataFrame â†’ Molecule dataclasses | Type-safe, clear semantics |
| **Persistence** | Atomic file writes (temp + replace) | Crash-safe, no corruption |
| **Process Model** | Single-threaded, sequential | Simple, deterministic, safe |
| **Logging** | Python logging | Structured, filterable |

### CLI Batch Progress Tracking

The CLI batch view renders a CSV-driven, 5-stage progress bar using a
daemon CSV poller and a thread-safe Queue. The tracker reads only the CSV
and never touches processing code directly.

Stages (CSV transitions):
1. `status`: `Pending`/`Selected` â†’ `Running` (RDKit parameters)
2. `crest_status`: `NOT_ATTEMPTED` â†’ `XTB_PREOPT` (pre-optimization; xTB if enabled)
3. `crest_status`: `XTB_PREOPT`/`NOT_ATTEMPTED` â†’ `CREST_SEARCH` (CREST search)
4. `mopac_status`: `NOT_ATTEMPTED` â†’ `RUNNING` (MOPAC PM7 calculation)
5. `status`: `Running` â†’ `OK` (final calculations)

Completion counters update when `status` reaches `OK`, `Rerun`, or `Skip`.
Final result values still use `crest_status` = `SUCCESS`/`FAILED` and
`mopac_status` = `OK`/`FAILED`.
The UI renders a 30-character bar (6 chars per stage) with a live spinner.

### Key Design Decisions

#### Decision 1: CSV as Source of Truth
- **Why:** Simple, auditable, versionable, human-readable
- **Tradeoff:** No concurrent access, no transactions
- **Constraint:** Must remain single-process

#### Decision 2: Atomic 1-Write-Per-Molecule
- **Why:** Ensures CSV never corrupted, even if process crashes
- **How:** Write to temp file, atomic rename (os.replace)
- **Guarantee:** Read after crash = always valid state

#### Decision 3: Type-Safe Dataclass Hierarchy
- **Why:** Catch errors at parse time, not runtime
- **Structure:** MoleculeIdentity + Properties + Results + Meta
- **Benefit:** IDE hints, mypy validation, clear schema

#### Decision 4: Settings as Typed Objects
- **Why:** Avoid dict access bugs (typos, wrong types)
- **Persistence:** TOML file, auto-loaded
- **Thread-Safe:** Immutable per-session (no concurrent updates)

#### Decision 5: Visibility First (Permissive Mode)
- **Why:** Recovery is good, but visibility is better
- **How:** Always print validation warnings + persistent logs
- **Monitoring:** grep logs for error patterns

---

## Known Limitations

### Limitation 1: CSV Backend is NOT Transactional

**Current State:**
```
âœ… Atomic writes (1 write/molecule)
âœ… Single-process safety
âœ… Crash-safe persistence
âŒ No file-level locking
âŒ No rollback capability
âŒ No concurrent access
```

**Why This Works Now:**
```
Single-process execution
  â†’ Only one writer at a time
  
Linear processing order
  â†’ Deterministic, no race conditions
  
Atomic writes (temp + replace)
  â†’ Even if crash mid-write, previous state intact
```

**Why This Will Break:**
```python
# DO NOT DO THIS (will corrupt data):
import multiprocessing

def process_mol(mol):
    mol.results.delta_1 = calculate(mol)
    persister.save_molecule(mol)

pool = multiprocessing.Pool(4)
pool.map(process_mol, molecules)  # â† BREAKS: no file locking
# Result: Molecules overwrite each other randomly
```

**What Happens:**
```
Process 1 reads CSV
Process 2 reads CSV (same version)
Process 1 updates mol_001, writes CSV
Process 2 updates mol_002, writes CSV  # â† Overwrites Process 1's work!
Result: mol_001 lost
```

**Solution Strategy (for future, NOT NOW):**

**Option A: SQLite (Recommended for â‰¤1M molecules)**
```python
# Future (v3.0+):
from grimperium.backends import SQLitePersister

persister = SQLitePersister("grimperium.db")
# Benefits: ACID, indexes, query support, concurrent reads
```

**Option B: PostgreSQL (For distributed)**
```python
# Future (v4.0+):
from grimperium.backends import PostgreSQLPersister

persister = PostgreSQLPersister("postgresql://...")
# Benefits: Full transactional, multi-server, scale unlimited
```

**Option C: Event Sourcing (For audit trail)**
```python
# Future (v3.5+):
from grimperium.backends import EventSourcingPersister

persister = EventSourcingPersister("grimperium.events")
# Benefits: Full history, temporal queries, no overwrites
```

**For Now (v2.2):**
- âœ… Use CSV with single-process
- âœ… Document this limitation (you're reading it)
- âŒ DO NOT attempt multiprocessing
- âŒ DO NOT run multiple instances on same data
- ğŸ”„ Migrate to SQLite if molecules exceed 100K

---

### Limitation 2: Permissive Mode Can Normalize Errors

**Problem:**
```
Day 1:  1 invalid row (perceptible)
Day 5:  15 invalid rows (normalizing)
Day 20: 200 invalid rows (invisible in logs)

Without monitoring, error pattern goes undetected
â†’ Future data may have systematic issues
```

**Mitigation (v2.2):**
```python
# Always printed to console + persisted to file
BatchOrchestrator prints:
1. Validation warnings (if strict=False)
2. Batch summary (always)
3. Errors (always)

Files created:
~/.grimperium/validation_errors.log  # All validation errors
~/.grimperium/batch_summary.log      # Run summaries
```

**Monitoring Strategy:**

```bash
# Check for increasing error rates:
grep "Skipped" ~/.grimperium/batch_summary.log | tail -10

# Find error patterns:
grep "timestamp_added" ~/.grimperium/validation_errors.log | wc -l

# Alert if errors exceed threshold:
if [ $(wc -l < ~/.grimperium/validation_errors.log) -gt 100 ]; then
  echo "WARNING: Many validation errors. Investigate CSV quality."
fi
```

**Human Review Checklist:**
- [ ] After first run: Review validation_errors.log
- [ ] Weekly: Check if error count stable
- [ ] If errors > 5% of total: Stop and investigate
- [ ] Monthly: Analyze batch_summary.log trends

---

### Limitation 3: BatchOrchestrator is Bottleneck for Parallelism

**Current Concentrates:**
```
BatchOrchestrator
â”œâ”€ Data loading
â”œâ”€ Scheduling
â”œâ”€ Execution (calls CalculationExecutor)
â”œâ”€ Status tracking
â”œâ”€ Persistence (atomic writes)
â””â”€ Summaries
```

**Why Problematic for Parallelism:**
```python
# Today: Sequential, all in orchestrator
for mol in scheduled:
    _process_molecule(mol)  # Happens in orchestrator

# Tomorrow (multiprocessing):
# If multiple processes call _process_molecule:
# - Status updates race
# - Persistence conflicts
# - Summary counts wrong
```

**Future Refactor Strategy (NOT NOW):**

**Phase 1: Extract concerns (v3.0)**
```python
# Separate responsibility:

class RerunManager:
     """Handle retry logic only"""
     def mark_retry(self, mol_id):
         self.retries[mol_id] += 1
    """Handle retry logic only"""
    def mark_retry(self, mol_id):
        self.retries[mol_id] += 1

class PersistenceQueue:
    """Thread-safe write queue"""
    def enqueue(self, mol):
        self.queue.put(mol)  # Thread-safe
    
    def worker(self):
        while True:
            mol = self.queue.get()
            persister.save_molecule(mol)  # Atomic

class BatchOrchestrator:
    """Coordinator only"""
    def run(self):
        # Just coordinate, don't execute
        for mol in scheduled:
            executor.submit(process_mol, mol)
            persistence_queue.enqueue(mol)
```

**Phase 2: Async I/O (v3.5)**
```python
# Use asyncio instead of threads:
async def run_batch():
    tasks = [
        executor.run_crest_async(mol)
        for mol in scheduled
    ]
    results = await asyncio.gather(*tasks)
```

**Phase 3: Distributed (v4.0)**
```python
# Move to task queue (Celery):
@task
def process_molecule(mol_id):
    # Runs on worker process
    mol = load_molecule(mol_id)
    calculate(mol)
    save_molecule(mol)

# Enqueue tasks
for mol_id in scheduled_ids:
    process_molecule.delay(mol_id)
```

**For Now (v2.2):**
- âœ… BatchOrchestrator runs sequentially
- âœ… Simple, safe, predictable
- âŒ DO NOT attempt parallelism without refactor
- ğŸ“ See Phase 1-3 above for future

---

## Data Flow

### Typical Batch Processing Flow

```
1. User runs: grimperium batch process

2. BatchOrchestrator.run()
   â”œâ”€ Step 1: Load CSV
   â”‚  â”œâ”€ CSVDataLoader.load_dataframe()
   â”‚  â”‚  â”œâ”€ Parse CSV
   â”‚  â”‚  â”œâ”€ Validate columns
   â”‚  â”‚  â””â”€ Validate rows (strict or permissive)
   â”‚  â”‚
   â”‚  â””â”€ BatchDataManager.load_batch()
   â”‚     â””â”€ For each CSV row:
   â”‚        â”œâ”€ Molecule.from_csv_dict(row)
   â”‚        â””â”€ MoleculeValueConverter handles:
   â”‚           â”œâ”€ Empty values â†’ (None, "empty")
   â”‚           â”œâ”€ Invalid values â†’ (None, "invalid") [log warning]
   â”‚           â”œâ”€ Zero values â†’ (0.0, None) [not falsy!]
   â”‚           â””â”€ NA markers ("nan", "none") â†’ (None, "invalid")
   â”‚
   â”œâ”€ Step 2: Print validation report (if errors)
   â”‚  â””â”€ Console: [YELLOW] âš ï¸ X rows skipped
   â”‚     File: ~/.grimperium/validation_errors.log
   â”‚
   â”œâ”€ Step 3: Schedule
   â”‚  â””â”€ BatchScheduler.schedule(molecules, max_reruns)
   â”‚     â”œâ”€ FAILED (reruns < max) â†’ Priority 1
   â”‚     â””â”€ PENDING â†’ Priority 2
   â”‚
   â”œâ”€ Step 4: For each scheduled molecule
   â”‚  â”œâ”€ Set status = RUNNING
   â”‚  â”œâ”€ CalculationExecutor.run_crest(mol)
   â”‚  â”‚  â”œâ”€ Run external CREST process (timeout)
   â”‚  â”‚  â”œâ”€ Parse output
   â”‚  â”‚  â””â”€ Update mol.results.crest_*
   â”‚  â”‚
   â”‚  â”œâ”€ CalculationExecutor.run_mopac_top_3(mol)
   â”‚  â”‚  â”œâ”€ Run MOPAC on 3 conformers
   â”‚  â”‚  â”œâ”€ Parse output
   â”‚  â”‚  â””â”€ Update mol.results.delta_1/2/3
   â”‚  â”‚
   â”‚  â””â”€ âœ… MoleculePersister.save_molecule(mol) [ATOMIC]
   â”‚     â”œâ”€ Read current CSV
   â”‚     â”œâ”€ Update mol's row
   â”‚     â”œâ”€ Write to temp file
   â”‚     â””â”€ Atomic rename (os.replace)
   â”‚        â†’ CSV never corrupted even if crash
   â”‚
   â”œâ”€ Step 5: Print batch summary
   â”‚  â””â”€ Console: ğŸ“Š {total, complete, errors, elapsed}
   â”‚     File: ~/.grimperium/batch_summary.log (append)
   â”‚
   â””â”€ Step 6: Return summary dict
      â””â”€ CLI displays results

3. Next run: Steps 1-6 again
   â†’ New molecules: status=PENDING
   â†’ Failed molecules: status=FAILED, reruns++
   â†’ Complete molecules: skipped (status=COMPLETE)
```

### Error Recovery Flow

```
Scenario: MOPAC times out for mol_001

Step 1: CalculationExecutor.run_mopac_top_3(mol_001)
        â†“
        raises CalculationError("MOPAC timeout")

Step 2: BatchOrchestrator._process_molecule catches error
        â”œâ”€ mol_001.meta.reruns += 1
        â”œâ”€ mol_001.meta.status = FAILED (if reruns < max_reruns)
        â”‚  or SKIPPED (if reruns >= max_reruns)
        â”œâ”€ mol_001.results.error_message = "MOPAC timeout"

Step 3: MoleculePersister.save_molecule(mol_001) [ATOMIC]
        â†’ CSV updated with FAILED status + retry count

Next Run:
  BatchScheduler.schedule() sees:
  â”œâ”€ mol_001 status=FAILED, reruns=1, max_reruns=3
  â””â”€ Eligible for rerun â†’ scheduled

Retry:
  CalculationExecutor tries again
  â†’ If succeeds: status=COMPLETE
  â†’ If fails again: reruns=2, FAILED again
  â†’ After 3 failures: status=SKIPPED (no more retries)
```

### CSV Format Evolution

**v2.0: Initial columns**
```csv
mol_id,status,reruns,smiles,multiplicity,charge,nheavy,timestamp_added,H298_cbs,batch_id
```

**v2.1: Added optional columns (backward compatible)**
```csv
...,timestamp_started,timestamp_completed,crest_status,crest_conformers_generated,
crest_time,mopac_status,mopac_time,delta_1,delta_2,delta_3,most_stable_hof,error_message
```

---

## Future Considerations

### If You Need to Parallelize

**Prerequisites (MANDATORY before parallelizing):**

1. **Add File Locking (MANDATORY)**
   ```python
   from filelock import FileLock
   
   with FileLock(self.csv_path + ".lock"):
       self.persister.save_molecule(mol)
   ```

   class RerunTracker:
   ```python
   # Separate thread-safe retry tracking
   class ReruntimeTracker:
       def __init__(self):
           self.lock = threading.Lock()
           self.retries = {}
       
       def increment_rerun(self, mol_id):
           with self.lock:
               self.retries[mol_id] = self.retries.get(mol_id, 0) + 1
   ```

3. **Make Summary Updates Atomic (MANDATORY)**
   ```python
   # Use Queue for summary updates
   self.summary_queue = queue.Queue()
   
   # Worker thread
   def summary_worker():
       while True:
           event = self.summary_queue.get()
           self.summary[event['key']] += event['value']
   ```



### If You Need to Scale Beyond CSV

**Recommended migration path:**

1. **100K molecules:** Optimize CSV
   - Index by mol_id
   - Cache hot rows
   - Maybe: JSONL (append-only) for new writes

2. **1M molecules:** SQLite
   ```python
   # Local SQLite DB (ACID, indexes, queries)
   # No network, runs on same machine
   db = sqlite3.connect("grimperium.db")
   # Full transactional support
   # Can use with multiprocessing
   ```

3. **10M molecules:** PostgreSQL
   ```python
   # Remote database
   # Full enterprise features
   # Distributed writes
   ```

4. **100M+ molecules:** Distributed system
   - Kafka for event log
   - Spark for analytics
   - Time-series DB for metrics

### If You Need Real-Time Monitoring

```python
# Add metrics collection:
class Metrics:
    def __init__(self):
        self.total_processed = 0
        self.total_errors = 0
        self.avg_time_per_mol = 0

# Export to monitoring system:
# - Prometheus (/metrics endpoint)
# - CloudWatch
# - DataDog
```

### If You Need Interactive Dashboard

```python
# Add REST API:
from fastapi import FastAPI

app = FastAPI()

@app.get("/api/batch/{batch_id}/status")
def get_batch_status(batch_id: str):
    return {"status": "running", "progress": 42}

# Serve web dashboard
# Real-time updates via WebSocket
```

---

## Decision Log

### Decision: Why CSV Over SQLite (for now)?

**Considered:** SQLite, PostgreSQL, MongoDB, JSONL

**Why CSV won:**
```
âœ… Human-readable (git-friendly)
âœ… Simple (no server, no setup)
âœ… Auditable (version control friendly)
âœ… Works offline
âœ… Excel-compatible (users can open/edit)
âŒ No transactions (documented)
âŒ No concurrency (documented)
```

**When to switch:**
- Molecules > 100K
- Need concurrent access
- Need transactional safety
- Need querying (SQLite wins)

---

### Decision: Why Atomic Writes?

**Problem:** CSV corruption if crash mid-write
```
Process writes:
  Line 1: mol_001,...   âœ“ written
  Line 2: mol_002,...   âœ“ written
  CRASH
  Line 3: mol_003,...   âœ— not written (corruption!)
```

**Solution:** Write to temp, atomic rename
```
Process writes to:
  ~/.temp_xyz.csv
  â”œâ”€ Line 1: mol_001
  â”œâ”€ Line 2: mol_002
  â”œâ”€ Line 3: mol_003
  â””â”€ Sync to disk
  
os.replace(temp, actual)  â† Atomic at OS level

If crash during replace:
  â†’ Old file still valid
  â†’ New file half-written, orphaned
```

**Guarantee:** Read after crash = always valid state

---

### Decision: Why Settings as TOML?

**Considered:** JSON, YAML, INI, Python files

**Why TOML:**
```
âœ… Human-readable
âœ… Typed values
âœ… Standard format
âœ… Comments allowed
âœ… Validated at parse time
âŒ Fewer editors than JSON
```

**Example:**
```toml
[calculation]
max_reruns = 3
crest_timeout_minutes = 30

[database]
data_dir = "data"
csv_file = "thermo_pm7.csv"
```

---

### Decision: Why Typed Dataclasses?

**Compared to:** dict access, Pydantic models

**Why dataclasses:**
```
âœ… IDE hints (autocomplete)
âœ… mypy validation (type checking)
âœ… Fast (no validation overhead)
âœ… Lightweight
âœ… Standard library (Python 3.7+)
âŒ Less validation than Pydantic
```

**Tradeoff:** Simplicity over features

---

## Appendix: Command Reference

### Run Batch Processing

```bash
# Standard (development, strict validation)
grimperium batch process

# Production (skip invalid rows, continue)
grimperium batch process --permissive

# Dry-run (no calculations, just load + schedule)
grimperium batch process --dry-run

# With custom settings
grimperium batch process --max-reruns 5 --crest-timeout 60
```

### View Logs

```bash
# Last 10 validation errors
tail -10 ~/.grimperium/validation_errors.log

# All summaries
cat ~/.grimperium/batch_summary.log

# Watch logs in real-time
tail -f ~/.grimperium/batch_summary.log
```

### Reset Configuration

```bash
# Show current settings
grimperium settings show

# Reset to defaults
rm ~/.grimperium/config.toml
```

### Database Operations

```bash
# Check CSV integrity
grimperium validate --strict

# Check CSV integrity (permissive)
grimperium validate --permissive

# Count molecules
grimperium info --count

# Export to other format
grimperium export --format json > molecules.json
```

---

## Questions & Answers

**Q: What if CSV gets corrupted?**
A: With atomic writes (v2.2), crash-safe. If corrupted manually: restore from git history.

**Q: Can I run two instances?**
A: NO. Not supported. You'll get random overwrites.

**Q: Can I use multiprocessing?**
A: NO. Not safe. Will corrupt CSV. Refactor Phase 1 required.

**Q: Can I edit CSV manually?**
A: YES, but: 1) Stop grimperium, 2) Edit, 3) Run grimperium validate --strict to check, 4) Resume.

**Q: How do I back up?**
A: CSV is your source. Commit to git. Or: `cp data/thermo_pm7.csv data/thermo_pm7.csv.backup.$(date +%s)`

**Q: What if molecule has delta_1=0.0?**
A: Valid! v2.2 handles correctly (not converted to None).

**Q: What about zero values in results?**
A: Also valid (energy can be zero). MoleculeValueConverter preserves.

---

**Document Version:** 2.2.0
**Last Updated:** 2026-01-19
**Next Review:** 2026-06-19 (or after 100K molecules processed)
