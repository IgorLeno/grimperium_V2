# üß™ Testing Guide - Post Round 2 Fixes

**Data**: 2026-01-13  
**Status**: Ready to test  
**Objetivo**: Verificar que os 28 fixes (19+9) funcionam em produ√ß√£o

---

## üìã PR√â-REQUISITOS

‚úÖ Round 1 (19 fixes) implementado  
‚úÖ Round 2 (9 fixes) implementado  
‚úÖ Linting passou (ruff)  
‚úÖ Functional verification passou (9/9)  

---

## üß™ FASE 1: SMOKE TEST (10 mol√©culas)

### Objetivo
Verificar que o sistema b√°sico funciona com dataset m√≠nimo.

### Comandos
```bash
# 1. Criar CSV de teste com 10 mol√©culas
python scripts/init_batch_csv.py \
  --input data/thermo_cbs_clean.csv \
  --output data/batch_test_10.csv \
  --limit 10

# 2. Verificar CSV criado
wc -l data/batch_test_10.csv  # Deve mostrar 11 linhas (header + 10)
head -n 2 data/batch_test_10.csv  # Ver header e primeira linha
```

### Verifica√ß√µes Esperadas
- ‚úÖ CSV criado com 11 linhas (1 header + 10 mol√©culas)
- ‚úÖ 33 colunas presentes
- ‚úÖ status = "Pending" (todos)
- ‚úÖ retry_count = 0 (todos)
- ‚úÖ OK enum value = "OK" (uppercase) - FIX 2
- ‚úÖ Nenhum erro de convers√£o - FIX 3
- ‚úÖ Mensagens de erro determin√≠sticas (se houver) - FIX 4

### Se Falhar
- Verificar se thermo_cbs_clean.csv existe
- Verificar se colunas "smiles" e "nheavy" existem
- Verificar logs de erro (sorted columns)

---

## üß™ FASE 2: SCALE TEST (40 mol√©culas)

### Objetivo
Testar state transitions e JSON detail files.

### Comandos
```bash
# 1. Criar CSV de teste com 40 mol√©culas
python scripts/init_batch_csv.py \
  --input data/thermo_cbs_clean.csv \
  --output data/batch_test_40.csv \
  --limit 40

# 2. [Aqui voc√™ rodaria o batch processing]
# Exemplo (quando tiver CLI):
# python -m grimperium.cli batch-run \
#   --csv data/batch_test_40.csv \
#   --batch-size 10 \
#   --crest-timeout 30 \
#   --mopac-timeout 60
```

### Verifica√ß√µes Esperadas
- ‚úÖ State transitions corretas:
  - PENDING ‚Üí SELECTED
  - SELECTED ‚Üí RUNNING
  - RUNNING ‚Üí OK/RERUN/SKIP
- ‚úÖ JSON detail files criados em data/conformer_details/
- ‚úÖ File descriptors n√£o vazam - FIX 1
- ‚úÖ _safe_int funciona com NaN - FIX 3, 5
- ‚úÖ CSV atualizado corretamente
- ‚úÖ retry_count incrementado corretamente - FIX 5
- ‚úÖ DEFAULT_MAX_OBSERVATIONS respeitado - FIX 6

### Monitoramento
```bash
# Durante execu√ß√£o, monitorar file descriptors
watch -n 1 'lsof -p $(pgrep -f python) | wc -l'

# Verificar se JSON detail files existem
ls -l data/conformer_details/*.json | wc -l

# Verificar status counts
cut -d',' -f10 data/batch_test_40.csv | sort | uniq -c
```

### Se Falhar
- Verificar logs de erro
- Verificar se file descriptors est√£o vazando (lsof)
- Verificar se JSON files est√£o corrompidos
- Verificar se retry_count est√° sendo incrementado

---

## üß™ FASE 3: PERFORMANCE ANALYSIS (100‚Üí1k‚Üí5k)

### Objetivo
Medir tempo por mol√©cula, mem√≥ria, file descriptor count.

### Comandos
```bash
# 1. Teste com 100 mol√©culas
python scripts/init_batch_csv.py \
  --input data/thermo_cbs_clean.csv \
  --output data/batch_test_100.csv \
  --limit 100

# 2. Monitorar recursos
/usr/bin/time -v python -m grimperium.cli batch-run \
  --csv data/batch_test_100.csv \
  --batch-size 20 \
  > performance_100.log 2>&1

# 3. Extrair m√©tricas
grep "Maximum resident set size" performance_100.log
grep "File descriptors" performance_100.log
```

### Verifica√ß√µes Esperadas
- ‚úÖ Tempo por mol√©cula: < 5 minutos (m√©dia)
- ‚úÖ Mem√≥ria: < 2GB RSS
- ‚úÖ File descriptors: < 100 (n√£o vaza) - FIX 1
- ‚úÖ Observations bounded: max 100 - FIX 6
- ‚úÖ Nenhum crash em CSV corrompido - FIX 3

### M√©tricas para Coletar
```python
# Ap√≥s batch processing
import pandas as pd
df = pd.read_csv('data/batch_test_100.csv')

# Success rate
success_rate = (df['status'] == 'OK').sum() / len(df) * 100
print(f"Success rate: {success_rate:.1f}%")

# Average time per molecule
avg_time = df['total_execution_time'].mean()
print(f"Average time: {avg_time:.1f}s")

# Status distribution
print(df['status'].value_counts())
```

---

## üß™ FASE 4: FULL PRODUCTION (30k mol√©culas)

### Objetivo
Rodar produ√ß√£o completa com monitoramento.

### Comandos
```bash
# 1. Criar CSV completo
python scripts/init_batch_csv.py \
  --input data/thermo_cbs_clean.csv \
  --output data/batch_30k.csv

# 2. Rodar em batches (exemplo: 500 mol√©culas por batch)
# Com checkpointing para poder retomar se falhar
for i in {1..60}; do
  echo "Batch $i/60"
  python -m grimperium.cli batch-run \
    --csv data/batch_30k.csv \
    --batch-size 500 \
    --crest-timeout 30 \
    --mopac-timeout 60 \
    >> production_30k.log 2>&1
  
  # Checkpoint: verificar status counts
  cut -d',' -f10 data/batch_30k.csv | sort | uniq -c
  
  sleep 5
done
```

### Monitoramento Cont√≠nuo
```bash
# Terminal 1: Tail logs
tail -f production_30k.log

# Terminal 2: Monitorar recursos
watch -n 10 'ps aux | grep python | grep -v grep'

# Terminal 3: Status dashboard
watch -n 30 'cut -d"," -f10 data/batch_30k.csv | sort | uniq -c'
```

### Verifica√ß√µes Esperadas
- ‚úÖ Nenhum crash por file descriptor leak - FIX 1
- ‚úÖ CSVs antigos carregam corretamente - FIX 2
- ‚úÖ CSV corrompido n√£o causa crash - FIX 3
- ‚úÖ Mensagens de erro determin√≠sticas - FIX 4
- ‚úÖ NaN handling correto - FIX 3, 5
- ‚úÖ Memory bounded - FIX 6
- ‚úÖ Type safety (sem exce√ß√µes de tipo) - FIX 7, 8
- ‚úÖ Documenta√ß√£o completa - FIX 9

### An√°lise Final
```python
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('data/batch_30k.csv')

# Success rate
success_rate = (df['status'] == 'OK').sum() / len(df) * 100
print(f"Success rate: {success_rate:.1f}%")

# Status distribution
print("\nStatus distribution:")
print(df['status'].value_counts())

# Timing statistics
print("\nTiming statistics:")
print(df['total_execution_time'].describe())

# Quality grades
print("\nQuality grades:")
print(df['quality_grade'].value_counts())

# Plot: nheavy vs execution time
plt.scatter(df['nheavy'], df['total_execution_time'], alpha=0.3)
plt.xlabel('Number of heavy atoms')
plt.ylabel('Total execution time (s)')
plt.title('Execution time vs molecule size')
plt.savefig('execution_time_vs_nheavy.png')
```

---

## üêõ DEBUGGING

### Se File Descriptor Leak (FIX 1)
```bash
# Monitorar FDs em tempo real
watch -n 1 'lsof -p $(pgrep -f python) | grep -E "json|tmp" | wc -l'

# Verificar se temp files est√£o sendo limpos
find data/conformer_details/ -name '.tmp_*' -ls
```

### Se CSV n√£o Carrega (FIX 2)
```python
# Verificar enum values
from grimperium.crest_pm7.batch.enums import MoleculeStatus
print(f"OK value: '{MoleculeStatus.OK.value}'")
assert MoleculeStatus.OK.value == "OK", "Must be uppercase!"

# Verificar CSV
import pandas as pd
df = pd.read_csv('data/batch_test_10.csv')
print(df['status'].unique())
```

### Se Crash em CSV Corrompido (FIX 3)
```python
# Testar _safe_int com valores problem√°ticos
from grimperium.crest_pm7.batch.csv_manager import BatchCSVManager
from pathlib import Path
import pandas as pd

mgr = BatchCSVManager(Path('/tmp/test.csv'))

# Test cases
test_values = [
    (pd.NA, "NaN"),
    (None, "None"),
    (float('nan'), "float NaN"),
    ("10", "string '10'"),
    ("3.5", "string '3.5'"),
    ("abc", "invalid string"),
    ("", "empty string"),
    ("  42  ", "whitespace string"),
]

for val, desc in test_values:
    result = mgr._safe_int(val, default=0)
    print(f"{desc:20s} ‚Üí {result}")
```

---

## ‚úÖ SUCCESS CRITERIA

### Smoke Test (Fase 1)
- [x] CSV criado com estrutura correta
- [x] 10 mol√©culas carregadas
- [x] Nenhum erro de parsing

### Scale Test (Fase 2)
- [ ] State transitions corretas
- [ ] JSON detail files criados
- [ ] File descriptors n√£o vazam
- [ ] CSV atualizado corretamente

### Performance (Fase 3)
- [ ] Tempo por mol√©cula < 5 min
- [ ] Mem√≥ria < 2GB
- [ ] File descriptors < 100

### Production (Fase 4)
- [ ] 30k mol√©culas processadas
- [ ] Success rate > 80%
- [ ] Nenhum crash
- [ ] Documenta√ß√£o completa

---

## üìû SUPORTE

Se encontrar problemas:

1. **Verificar logs**: `tail -f production_30k.log`
2. **Verificar status**: `cut -d',' -f10 data/batch_30k.csv | sort | uniq -c`
3. **Verificar FDs**: `lsof -p $(pgrep -f python) | wc -l`
4. **Consultar docs**: 
   - `docs/FIXES-2026-01-13.md` (todos os 28 fixes)
   - `docs/FIXES-ROUND2-SUMMARY.md` (Round 2 espec√≠fico)

---

**√öltima atualiza√ß√£o**: 2026-01-13  
**Status**: Ready to test üöÄ
